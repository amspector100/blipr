[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 blipr authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/blipr-changepoint.html","id":"problem-setting","dir":"Articles","previous_headings":"","what":"Problem setting","title":"BLiP for change-point detection","text":"Given time series data \\((Y_1, \\dots, Y_n)\\), suppose interested looking “change-points”, times stochastic process changes. Often, can tell process changed, discern exactly changed observation \\(\\{Y_i\\}\\) noisy. following synthetic dataset gives one example :","code":"library(tidyverse) #> ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── #> ✓ ggplot2 3.3.4     ✓ purrr   0.3.4 #> ✓ tibble  3.1.2     ✓ dplyr   1.0.7 #> ✓ tidyr   1.1.3     ✓ stringr 1.4.0 #> ✓ readr   1.4.0     ✓ forcats 0.5.1 #> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #> x dplyr::filter() masks stats::filter() #> x dplyr::lag()    masks stats::lag() library(blipr)  # Generate synthetic data set.seed(1234) n <- 200  data <- blipr::generate_changepoint_data(   n=n, sparsity=0.04, tau2=4 ) df <- data.frame(   Time=c(1:n),   Y=data$y, # observed data   beta=data$beta, # change points   mu=data$mu # mean of Y )  # Plot data ggplot(df, aes(x=Time)) +    geom_point(aes(y=Y, color='Y')) +   geom_line(aes(y=mu, color='E[Y]')) +    scale_color_manual(values=c(\"Y\"='blue', 'E[Y]'='red'))"},{"path":"/articles/blipr-changepoint.html","id":"applying-blip","dir":"Articles","previous_headings":"","what":"Applying BLiP","title":"BLiP for change-point detection","text":"detect regions true mean \\(Y\\) changed, first use bcp package fit Bayesian change-point detection model. , can apply BLiP directly top posterior samples. can plot detections check true false positives.  shown , BLiP detected change-points highlighted regions. case, turns BCP + BLiP made true discoveries.","code":"# Fit Bayesian change point model, running 10 chains of 2K samples each library(bcp) #> Loading required package: grid post_samples <- matrix(nrow=0, ncol=n) N <- 2000; burnin <- N/10; chains <- 10 for (i in 1:chains) {   bcp_out <- bcp(y=data$y, return.mcmc=T, mcmc=N, burnin=burnin, p0=0.1)   post_samples <- rbind(     post_samples, t(bcp_out$mcmc.rhos[,(burnin+1):(N+burnin)])   ) } # Shift by one to ensure indexing conventions line up post_samples <- cbind(   matrix(0, dim(post_samples)[1], 1),    post_samples[,0:(n-1)] )  # Create candidate groups and apply BLiP cand_groups <- sequential_groups(samples=post_samples, max_pep=0.5) detections <- blipr::BLiP(cand_groups=cand_groups) # True change-points cps <- which(df$beta != 0) # Process detections detection_df <- data.frame(   start=sapply(detections, function(x) {min(x$group)}),   end=sapply(detections, function(x) {max(x$group)}),   true_disc=sapply(detections, function(x) {     length(intersect(x$group, cps)) > 0   } )) %>% mutate(true_disc=ifelse(true_disc, \"True\", \"False\")) # Plot ggplot(df) +    geom_point(aes(x=Time, y=Y, color='Y')) +   geom_line(aes(x=Time, y=mu, color='E[Y]')) +    geom_rect(data=detection_df, mapping=aes(       xmin=start, xmax=end + 1,       ymin=min(df$Y), ymax=max(df$Y),       fill=true_disc, alpha=1/(2*(end-start+1)),     ),   ) +   scale_color_manual(values=c(\"Y\"='blue', 'E[Y]'='red')) +    scale_fill_manual(values=c(\"True\"=\"forestgreen\", \"False\"=\"orange\")) +   labs(fill='True Discovery') +   scale_alpha(guide='none')"},{"path":"/articles/blipr-regression.html","id":"problem-setting","dir":"Articles","previous_headings":"","what":"Problem setting","title":"BLiP for controlled variable selection","text":"Suppose observe highly correlated covariates \\(X = (X_1, \\dots, X_p)\\) response \\(Y\\), seek discover covariates \\(X_j\\) “important” sense controlling false discovery rate. High correlations make challenging detect individually important covariates, resolution-adaptive variable selection aims detect disjoint groups variables detected group contains least one important variable high confidence. course, BLiP make detected group small possible, discover individual signal variables possible.","code":""},{"path":"/articles/blipr-regression.html","id":"synthetic-data","dir":"Articles","previous_headings":"","what":"Synthetic data","title":"BLiP for controlled variable selection","text":", generate synthetic data highly correlated covariates \\(X = (X_1, \\dots, X_p)\\) response \\(Y\\), \\(Y \\mid X \\sim \\mathcal{N}(X \\beta, \\sigma^2)\\) follows Gaussian linear model sparse coefficients. say \\(X_j\\) signal variable \\(\\beta_j \\ne 0\\).","code":"library(blipr) set.seed(123); n <- 100; p <- 200 data <- blipr::generate_regression_data(n=n, p=p)  # Show heatmap of correlation matrix library(RColorBrewer) colormap <-colorRampPalette(c(\"red\",\"white\",\"blue\"))(100) pheatmap::pheatmap(   cor(data$X),   breaks=c(0:100 - 50)/50,   color=colormap,   cluster_rows=F,   cluster_cols=F,   main='Correlation matrix of X' )"},{"path":"/articles/blipr-regression.html","id":"example-1-linear-spike-and-slab-model-blip","dir":"Articles","previous_headings":"","what":"Example 1: Linear spike-and-slab model + BLiP","title":"BLiP for controlled variable selection","text":"can run BLiP two steps. First, fit Bayesian model \\((X, Y)\\)—case, use spike--slab model sparse linear regression. Second, run BLiP directly top posterior samples Bayesian model, shown . Second, apply BLiP post_samples. Since synthetic dataset, can check whether detections BLiP correct. Lastly, since synthetic dataset, can check whether detections BLiP correct.","code":"# Step 1: fit a spike-and-slab model using NPrior. This takes ~30 seconds. # devtools::install_github(\"rabbitinasubmarine/NPrior\") nprior <- NPrior::NPrior_run(    X=data$X, y=data$y, N=5000, prior='SpSL-G', verbose=0 ) post_samples <- t(nprior$ThetaSamples) # Step 2: apply BLiP detections <- blipr::BLiP(   samples=post_samples, error='fdr', q=0.1, max_pep=0.5 ) # Check whether detections are correct check_correctness <- function(detections, beta) {  signals <- which(beta != 0)   for (j in 1:length(detections)) {     group <- detections[[j]]$group     pgroup <- paste(\"{\", paste(group, collapse=\", \"), \"}\", sep='')     correct <- ifelse(       length(intersect(signals, group)) > 0,        \"correctly\",        \"incorrectly\"     )     cat(\"BLiP \", correct, \" detected a signal in \", pgroup, \".\\n\", sep='')   }  } check_correctness(detections, data$beta) #> BLiP correctly detected a signal in {106}. #> BLiP correctly detected a signal in {136}. #> BLiP correctly detected a signal in {193, 194}. #> BLiP correctly detected a signal in {95, 96, 97, 98, 99, 100}. #> BLiP correctly detected a signal in {5}. #> BLiP correctly detected a signal in {141}. #> BLiP correctly detected a signal in {53, 54, 55, 56, 57}."},{"path":"/articles/blipr-regression.html","id":"example-2-susie-blip","dir":"Articles","previous_headings":"","what":"Example 2: SuSiE + BLiP","title":"BLiP for controlled variable selection","text":"BLiP can apply top nearly Bayesian model algorithm, including variational algorithms. , show apply BLiP top SuSiE model (Wang et al, 2020). three steps: Step 1 fit SuSiE, Step 2 create candidate groups based SuSiE outputs, Step 3 apply BLiP. can see , SuSiE + BLiP localizes signals precisely SuSiE alone.","code":"# Step 1: fit SuSiE # install.packages(\"susieR\") susie_fit <- susieR::susie(X=data$X, y=data$y, L=10)  # Step 2: Create candidate groups cand_groups <- blipr::susie_groups(   susie_fit$alpha, X=data$X, q=0.1 )  # Step 3: fit BLiP detections <- blipr::BLiP(   cand_groups=cand_groups,q=0.1, error='fdr', max_pep=0.5 ) cat(\"The signals are\", which(data$beta != 0), \"\\n\") #> The signals are 5 14 20 54 98 106 136 141 164 193 cat(\"The SuSiE detections are: \") #> The SuSiE detections are: n <- lapply(   susie_fit$sets$cs,    function(x) {cat(\"{\", paste(x, collapse=', '), \"} \", sep='')} ) #> {136} {106} {5, 6} {193, 194} cat(\"\\nThe SuSiE + BLiP detections are: \") #>  #> The SuSiE + BLiP detections are: n <- lapply(   detections,    function(x) {cat(\"{\", paste(x$group, collapse=', '), \"} \", sep='')} ) #> {136} {106} {5} {193, 194}"},{"path":"/articles/blipr-regression.html","id":"example-3-spike-and-slab-probit-regression","dir":"Articles","previous_headings":"","what":"Example 3: Spike-and-slab probit regression","title":"BLiP for controlled variable selection","text":"can run BLiP top nearly regression model, including various models binary responses. example, suppose observe binary indicator \\(Y^{\\star}\\) outcome. can apply BLiP directly top sparse probit model setting, shown .","code":"# install.packages(\"BoomSpikeSlab\") # Generate probit data set.seed(123) pdata <- blipr::generate_regression_data(n=300, p=200)  # Step 1: fit probit model using 5 chains of 2000 samples ystar <- pdata$y > 0 chains <- 10; niter <- 2000 post_samples <- matrix(0, 0, p) for (c in 1:chains) {   probit_model <- BoomSpikeSlab::probit.spike(     ystar ~ pdata$X - 1, niter=niter, ping=-1, seed=123, expected.model.size=10   )   post_samples <- rbind(post_samples, probit_model$beta) } # Step 2: run BLiP on the posterior samples detections <- blipr::BLiP(samples=post_samples, q=0.1, error='fdr') check_correctness(detections, pdata$beta) #> BLiP correctly detected a signal in {181}. #> BLiP correctly detected a signal in {154, 155}. #> BLiP correctly detected a signal in {109, 110}. #> BLiP correctly detected a signal in {87}. #> BLiP correctly detected a signal in {187}. #> BLiP incorrectly detected a signal in {7, 8}."},{"path":"/articles/blipr-regression.html","id":"discussion-using-hierarchical-priors-to-avoid-misspecification","dir":"Articles","previous_headings":"","what":"Discussion: Using hierarchical priors to avoid misspecification","title":"BLiP for controlled variable selection","text":"BLiP can wrap top nearly Bayesian model, practice, fairly robust degree model misspecification (see paper simulations discussion issue). said, underlying model extremely poorly specified, BLiP violate FDR control. example, following problem, prior indicates \\(50\\%\\) variables signal variables, whereas truth \\(5\\%\\) variables signal variables. can see, many detections false positives due misspecified model. avoid situation, recommend using hierarchical priors unknown nuisance parameters like sparsity level regression problems conservative choice hyperparameters. See Spector Janson (2022) discussion issue concrete suggestion hierarchical priors generalized linear models. using MCMC algorithms, also recommend running multiple MCMC chains different initializations protect convergence issues discussed paper, even individual MCMC chain fails converge, often using multiple chains overstate uncertainty location signals, leading conservative valid inference.","code":"# Sample from an obviously bad spike and slab model lm_bad <- BoomSpikeSlab::lm.spike(   data$y ~ data$X - 1, niter=2000, ping=-1, expected.model.size=100,  ) detections_bad <- blipr::BLiP(samples=lm_bad$beta, q=0.1, error='fdr') check_correctness(detections_bad, data$beta) #> BLiP correctly detected a signal in {106}. #> BLiP correctly detected a signal in {136}. #> BLiP correctly detected a signal in {5, 6}. #> BLiP correctly detected a signal in {95, 96, 97, 98, 99, 100}. #> BLiP correctly detected a signal in {53, 54, 55, 56}. #> BLiP correctly detected a signal in {8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28}. #> BLiP incorrectly detected a signal in {60, 140}. #> BLiP incorrectly detected a signal in {111}. #> BLiP incorrectly detected a signal in {4, 78}. #> BLiP correctly detected a signal in {193, 194}. #> BLiP correctly detected a signal in {141, 190}."},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Asher Spector. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Asher Spector Lucas Janson (2022). Controlled Discovery Localization Signals via Bayesian Linear Programming","code":"@Article{,   title = {Controlled Discovery and Localization of Signals via Bayesian Linear Programming},   author = {Asher Spector and Lucas Janson},   journal = {arXiv preprint arXiv:2203.17208},   url = {https://arxiv.org/abs/2203.17208},   year = {2022}, }"},{"path":[]},{"path":"/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"A Bayesian Linear Program for resolution-adaptive signal detection","text":"many applications, can tell signal interest exists perfectly “localize” . example, regressing outcome Y highly correlated covariates (X1, X2), data may suggest least one (X1, X2) influences Y, may challenging tell (X1, X2) important. Likewise, genetic fine-mapping, biologists may high confidence gene influences disease without knowing precisely genetic variants cause disease. Similar problems arise many settings spatial temporal structure, including change-point detection astronomical point-source detection. Bayesian Linear Programming (BLiP) method jointly detects many signals possible localizing precisely possible. BLiP can wrap top nearly Bayesian model algorithm, return set regions contain least one signal high confidence. example, regression problems, BLiP might return region (X1, X2), suggests least one (X1, X2) important variable. BLiP controls false discovery rate also making regions narrow possible, meaning (roughly speaking) perfectly localize signals whenever possible! blipr efficient python implementation BLiP, designed BLiP can wrap top Bayesian model one two lines code.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Bayesian Linear Program for resolution-adaptive signal detection","text":"can install blipr GitHub:","code":"# install.packages(\"remotes\") remotes::install_github(\"amspector100/blipr\")"},{"path":"/index.html","id":"minimal-example","dir":"","previous_headings":"","what":"Minimal example","title":"A Bayesian Linear Program for resolution-adaptive signal detection","text":", apply BLiP perform variable selection sparse linear regression. first step generate synthetic data fit Bayesian model using, e.g., NPrior package.","code":"# Generate sparse linear regression data set.seed(123); n <- 100; p <- 200 data <- blipr::generate_regression_data(n=n, p=p)  # Fit a Bayesian spike-and-slab model nprior <- NPrior::NPrior_run(    X=data$X, y=data$y, N=5000, prior='SpSL-G' ) post_samples <- t(nprior$ThetaSamples)  # Run BLiP on the posterior samples detections <- blipr::BLiP(   samples=post_samples, q=0.1, error='fdr' ) for (j in 1:length(detections)) {   group <- paste(detections[[j]]$group, collapse=', ')   cat(\"BLiP has detected a signal in \", group, \".\\n\", sep='') }"},{"path":"/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"A Bayesian Linear Program for resolution-adaptive signal detection","text":"Documentation tutorials available amspector100.github.io/blipr.","code":""},{"path":"/index.html","id":"reference","dir":"","previous_headings":"","what":"Reference","title":"A Bayesian Linear Program for resolution-adaptive signal detection","text":"use blipr BLiP academic publication, please consider citing Spector Janson (2022). bibtex entry :","code":"@article{AS-LJ:2022,   title={Controlled Discovery and Localization of Signals via Bayesian Linear Programming},   author={Spector, Asher and Janson, Lucas},   journal={arXiv preprint arXiv:2203.17208},   url={https://arxiv.org/abs/2203.17208},   year={2022} }"},{"path":"/reference/BLiP.html","id":null,"dir":"Reference","previous_headings":"","what":"Given samples from a posterior or a list of candidate groups, BLiP performs\nresolution-adaptive signal detection to maximize power while controlling\n(e.g.) the FDR. — BLiP","title":"Given samples from a posterior or a list of candidate groups, BLiP performs\nresolution-adaptive signal detection to maximize power while controlling\n(e.g.) the FDR. — BLiP","text":"Given samples posterior list candidate groups, BLiP performs resolution-adaptive signal detection maximize power controlling (e.g.) FDR.","code":""},{"path":"/reference/BLiP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Given samples from a posterior or a list of candidate groups, BLiP performs\nresolution-adaptive signal detection to maximize power while controlling\n(e.g.) the FDR. — BLiP","text":"","code":"BLiP(   samples = NULL,   cand_groups = NULL,   weight_fn = \"inverse_size\",   error = \"fdr\",   q = 0.1,   max_pep = 1,   deterministic = T,   verbose = F,   perturb = T,   max_iters = 100,   search_method = \"binary\",   solver = NULL )"},{"path":"/reference/BLiP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Given samples from a posterior or a list of candidate groups, BLiP performs\nresolution-adaptive signal detection to maximize power while controlling\n(e.g.) the FDR. — BLiP","text":"samples (N,p)-shaped matrix posterior samples nonzero value indicates presence signal. cand_groups list lists, inner lists must \"group\" attribute, corresponding features group \"pep\" attribute, corresponding posterior error probability. weight_fn weight discoveries. Can one 'inverse_size' 'log_inverse_size' function takes candidate group input returns weight. error Bayesian error rate control: one \"fwer\", \"pfer\", \"fdr\", \"local_fdr\". q level control Bayesian FWER/PFER/FDR/local FDR. max_pep Never select group pep greater max_pep. deterministic Whether BLiP return deterministic solution. verbose TRUE, gives occasional progress reports. perturb TRUE, adds tiny (random) perturbation weights ensure existence unique optimal solution. max_iters Maximum number binary-search iterations FWER . search_method FWER control, find optimal parameter LP. Either 'binary' (defalt) 'none'. solver solver use within CVXR. default, use Gurobi, CBC, ECOS (order), depending whether installed.","code":""},{"path":"/reference/BLiP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Given samples from a posterior or a list of candidate groups, BLiP performs\nresolution-adaptive signal detection to maximize power while controlling\n(e.g.) the FDR. — BLiP","text":"list candidate groups, asserts group contains signal.","code":""},{"path":"/reference/BLiP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Given samples from a posterior or a list of candidate groups, BLiP performs\nresolution-adaptive signal detection to maximize power while controlling\n(e.g.) the FDR. — BLiP","text":"","code":"# Example 1: sparse linear regression set.seed(123); n <- 100; p <- 200 data <- blipr::generate_regression_data(n=n, p=p) # sample from the posterior, e.g., using NPrior nprior <- NPrior::NPrior_run(   X=data$X, y=data$y, N=5000, prior='SpSL-G' ) #> Error in NPrior::NPrior_run(X = data$X, y = data$y, N = 5000, prior = \"SpSL-G\"): object 'n' not found # run blip on posterior samples detections <- blipr::BLiP(samples=t(nprior$ThetaSamples), q=0.1, error='fdr') #> Error in t(nprior$ThetaSamples): object 'nprior' not found  # Example 2: Running BLiP directly on candidate groups cand_groups <- list(   list(group=c(1), pep=0.1),   list(group=c(2), pep=0.5),   list(group=c(1,2), pep=0.01)  ) detections <- blipr::BLiP(cand_groups=cand_groups, q=0.1, error='fdr')"},{"path":"/reference/dist_matrix_to_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates groups based on dist_matrix using hierarchical clustering — dist_matrix_to_groups","title":"Creates groups based on dist_matrix using hierarchical clustering — dist_matrix_to_groups","text":"Creates groups based dist_matrix using hierarchical clustering","code":""},{"path":"/reference/dist_matrix_to_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates groups based on dist_matrix using hierarchical clustering — dist_matrix_to_groups","text":"","code":"dist_matrix_to_groups(dist_matrix)"},{"path":"/reference/dist_matrix_to_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates groups based on dist_matrix using hierarchical clustering — dist_matrix_to_groups","text":"dist_matrix distance matrix object","code":""},{"path":"/reference/elim_redundant_features.html","id":null,"dir":"Reference","previous_headings":"","what":"After prefiltering groups, some features/locations\nmay not appear in any candidate groups. When this happens,\nthis function reindexes the locations to improve efficiency. — elim_redundant_features","title":"After prefiltering groups, some features/locations\nmay not appear in any candidate groups. When this happens,\nthis function reindexes the locations to improve efficiency. — elim_redundant_features","text":"prefiltering groups, features/locations may appear candidate groups. happens, function reindexes locations improve efficiency.","code":""},{"path":"/reference/elim_redundant_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"After prefiltering groups, some features/locations\nmay not appear in any candidate groups. When this happens,\nthis function reindexes the locations to improve efficiency. — elim_redundant_features","text":"","code":"elim_redundant_features(cand_groups)"},{"path":"/reference/generate_changepoint_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate synthetic change point data. — generate_changepoint_data","title":"Generate synthetic change point data. — generate_changepoint_data","text":"Generate synthetic change point data.","code":""},{"path":"/reference/generate_changepoint_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate synthetic change point data. — generate_changepoint_data","text":"","code":"generate_changepoint_data(n = 100, sparsity = 0.01, tau2 = 1)"},{"path":"/reference/generate_changepoint_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate synthetic change point data. — generate_changepoint_data","text":"n Number data points sparsity Proportion change points tau2 Size change points","code":""},{"path":"/reference/generate_regression_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate synthetic sparse regression data. — generate_regression_data","title":"Generate synthetic sparse regression data. — generate_regression_data","text":"Generate synthetic sparse regression data.","code":""},{"path":"/reference/generate_regression_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate synthetic sparse regression data. — generate_regression_data","text":"","code":"generate_regression_data(   n = 100,   p = 500,   a = 5,   b = 1,   sparsity = 0.05,   coeff_size = 1 )"},{"path":"/reference/generate_regression_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate synthetic sparse regression data. — generate_regression_data","text":"n Number data points p Dimensionality Correlations sampled Beta(,b) random variables. b Correlations sampled Beta(,b) random variables. sparsity Proportion nonzero coefficients. coeff_size Size coefficients","code":""},{"path":"/reference/hierarchical_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates hierarchically structured candidate groups\nbased on a distance matrix. — hierarchical_groups","title":"Creates hierarchically structured candidate groups\nbased on a distance matrix. — hierarchical_groups","text":"Creates hierarchically structured candidate groups based distance matrix.","code":""},{"path":"/reference/hierarchical_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates hierarchically structured candidate groups\nbased on a distance matrix. — hierarchical_groups","text":"","code":"hierarchical_groups(   samples,   dist_matrix = NULL,   X = NULL,   max_pep = 1,   max_size = 25,   filter_sequential = FALSE )"},{"path":"/reference/hierarchical_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates hierarchically structured candidate groups\nbased on a distance matrix. — hierarchical_groups","text":"samples (N,p)-shaped array posterior samples nonzero value indicates presence signal. dist_matrix distance matrix corresponding distances locations, used hierarchical clustering. X design matrix regression problems, used create dist_matrix dist_matrix provided. max_pep maximum posterior error probability (PEP) allowed candidate group. Default 1. max_size maximum allowable size group. filter_sequential TRUE, ignore sequential groups variables avoid duplication.","code":""},{"path":"/reference/prefilter.html","id":null,"dir":"Reference","previous_headings":"","what":"Eliminate cand_groups with pep < max_pep — prefilter","title":"Eliminate cand_groups with pep < max_pep — prefilter","text":"Eliminate cand_groups pep < max_pep","code":""},{"path":"/reference/prefilter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eliminate cand_groups with pep < max_pep — prefilter","text":"","code":"prefilter(cand_groups, max_pep)"},{"path":"/reference/sequential_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates all sequential candidate groups below max_size. — sequential_groups","title":"Calculates all sequential candidate groups below max_size. — sequential_groups","text":"Calculates sequential candidate groups max_size.","code":""},{"path":"/reference/sequential_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates all sequential candidate groups below max_size. — sequential_groups","text":"","code":"sequential_groups(   samples = NULL,   susie_alphas = NULL,   q = 0,   max_pep = 1,   max_size = 25,   prenarrow = TRUE )"},{"path":"/reference/sequential_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates all sequential candidate groups below max_size. — sequential_groups","text":"samples (N,p)-shaped matrix posterior samples nonzero value indicates presence signal. susie_alphas alternative posterior samples, users may specify L x p matrix alphas SuSiE object. However, calling susie_groups recommended instead. q nominal level control error rate (optional) max_pep maximum posterior error probability (PEP) allowed candidate group. Default 1. max_size maximum allowable size group. prenarrow true, prenarrows candidate groups described paper. Defaults TRUE.","code":""},{"path":"/reference/susie_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates candidate groups based on a SuSiE model — susie_groups","title":"Creates candidate groups based on a SuSiE model — susie_groups","text":"Creates candidate groups based SuSiE model","code":""},{"path":"/reference/susie_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates candidate groups based on a SuSiE model — susie_groups","text":"","code":"susie_groups(alphas, X, q, max_pep = 1, max_size = 25, prenarrow = TRUE)"},{"path":"/reference/susie_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates candidate groups based on a SuSiE model — susie_groups","text":"alphas L x p matrix alphas SuSiE object. X N x p design matrix. NULL, also add hierarchical groups based correlation cluster X. q nominal level control error rate max_pep maximum posterior error probability (PEP) allowed candidate group. Default 1. max_size maximum allowable size group. prenarrow true, prenarrows candidate groups described paper. Defaults TRUE.","code":""}]
